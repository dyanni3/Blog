{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SENN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dyanni3/Blog/blob/master/SENN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "LrKN0KpzayGt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " \n",
        "##1.   Creating the Autoencoder for basis concepts using MNIST as example \n",
        "\n",
        "\n",
        "\n",
        "First going to create the simplest possible autoencoder. It's a fully connected layer as the encoder and decoder"
      ]
    },
    {
      "metadata": {
        "id": "ui0MaQ41dRU4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The way to train the autoencoder is to make the y_train data be exactly the x_train data. i.e. you want to do a reconstruction, so you want the output to equal the input.\n"
      ]
    },
    {
      "metadata": {
        "id": "MMi_ESOBgbCx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Sparsity:\n",
        "\n",
        "The encoded images do not look very sparse. For the purpose of explainable AI we don't only want a low reconstruction error, we also want the encoded units to represent *concepts*. In order for that to be the case it's best if a given input highly activates only few encoded units. For example for the mnist dataset it would be very natural for the autoencoder to learn ten concepts (one for each digit) just like a human. Then activation of the encoded units would be sparse (mostly just one unit activated for any given input image). Of course, to actually achieve this we'd likely need to force the encoded dimension to be exactly 10. This is pretty unlikely for an arbitrary dataset. Presumably we could discover structure in the data during EDA (e.g. by doing some clustering), but anyway the principle is that sparsity *should* give us reasonably coherent concepts - to the extent that the data allow.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "8vuXrDRIBK_R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Autoencoder Architecture](https://softmattermachines.files.wordpress.com/2019/01/autoencoder.png)"
      ]
    },
    {
      "metadata": {
        "id": "AOdXldnTg71Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### making the autoencoder with tensorflow ######\n",
        "\n",
        "#imports\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dense, Input, Dropout\n",
        "from keras.models import Model\n",
        "from keras import datasets\n",
        "from keras import regularizers\n",
        "\n",
        "#load data\n",
        "mnist = datasets.mnist\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "#reshape data and prep\n",
        "x_train = np.reshape(x_train,(len(x_train),784))\n",
        "x_test = np.reshape(x_test,(len(x_test),784))\n",
        "encoding_dim_1 = 164\n",
        "encoding_dim_2 = 10\n",
        "\n",
        "#set up models\n",
        "input_img = Input(shape = (784,))\n",
        "encoded = Dense(encoding_dim_1, activation = 'relu')(input_img)\n",
        "encoded = Dropout(.3)(encoded)\n",
        "encoded = Dense(encoding_dim_2,activation='relu',\n",
        "               activity_regularizer=regularizers.l1(2.5e-6))(encoded)\n",
        "decoded = Dense(encoding_dim_1, activation = 'relu')(encoded)\n",
        "#decoded = Dropout(.3)(decoded)\n",
        "decoded = Dense(784,activation='sigmoid')(decoded)\n",
        "autoencoder = Model(input_img,decoded)\n",
        "encoder = Model(input_img,encoded)\n",
        "decoder_layer_1 = autoencoder.layers[-2]\n",
        "decoder_layer_2 = autoencoder.layers[-1]\n",
        "encoded_input = Input(shape = (encoding_dim_2,))\n",
        "decoder = Model(encoded_input, decoder_layer_2(decoder_layer_1(encoded_input)))\n",
        "\n",
        "#compile and fit\n",
        "autoencoder.compile(optimizer='adadelta', loss = 'binary_crossentropy')\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=1,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                verbose=2,\n",
        "                validation_data=(x_test, x_test))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OgmptoCdCLCl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#predict and plot\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)\n",
        "fig,ax = plt.subplots(nrows=3,ncols=10)\n",
        "for j in range(3):\n",
        "  for i in range(10):\n",
        "    #plot the input\n",
        "    ax[0][i].imshow(x_test[i].reshape(28,28),cmap=plt.cm.gray)\n",
        "    #plot the reconstructed image\n",
        "    ax[1][i].imshow(decoded_imgs[i].reshape(28,28),cmap = plt.cm.gray)\n",
        "    #plot the encoded image\n",
        "    ax[2][i].bar(np.arange(10),encoded_imgs[i].reshape(10,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zu1B6ecaCNY_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vJnfi6vEMUWY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Not too shabby! Note that we don't need the reconstructions to be perfect, because in the end we're going to pair these with generalized weights to make predictions. What we need from the reconstructions is for them to be human understandable, each basis concept should be something interpretable!\n",
        "\n",
        "Still, since the input are images, we can do much better for this data set with a convolutional autoencoder. Something like the following architecture.\n",
        "\n",
        "![conv_autoencoder](https://softmattermachines.files.wordpress.com/2019/01/conv_autoencoder.png)"
      ]
    },
    {
      "metadata": {
        "id": "lf9phLiRM3NY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "encoded = Dense(10,activation='relu',\n",
        "               activity_regularizer=regularizers.l1(2.5e-6))(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n",
        "\"\"\"encoder = Model(input_img, encoded)\n",
        "encoded_input = Input(shape=(10,))\n",
        "decoder_layers = autoencoder.layers[7:]\n",
        "x = decoder_layers[0](encoded_input)\n",
        "for i in range(1,6):\n",
        "  x = decoder_layers[i](x)\n",
        "decoder_output = decoder_layers[6](x)\n",
        "decoder = Model(encoded_input,decoder_output)\"\"\"\n",
        "\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tf8to5xcgpA6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history = autoencoder.fit(x_train, x_train,\n",
        "                epochs=1,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                verbose=1,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7RYvhzkA1av-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['val_loss'],label = \"validation\")\n",
        "plt.plot(history.history['loss'],label = \"training\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5QRTG7u11gUn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(1,n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mdR-v4hL13X3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder = Model(input_img, encoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gvceqqg9QASD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoded_preds = encoder.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uvBSWGsCQFMU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(figsize=(20,2),nrows=1, ncols=10)\n",
        "for i in range(10):\n",
        "  for j in range(4):\n",
        "    for k in range(4):\n",
        "      axes[i].bar(np.arange(10),encoded_preds[i,j,k])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tkJs8W6JQOc1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoded_preds.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ESRFSxfvR_oD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}